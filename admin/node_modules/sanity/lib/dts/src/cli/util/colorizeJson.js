import tokenize from 'json-lexer';
const identity = (inp) => inp;
export function colorizeJson(input, chalk) {
    const formatters = {
        punctuator: chalk.white,
        key: chalk.white,
        string: chalk.green,
        number: chalk.yellow,
        literal: chalk.bold,
        whitespace: identity,
    };
    const json = JSON.stringify(input, null, 2);
    return tokenize(json)
        .map((token, i, arr) => {
        // Note how the following only works because we pretty-print the JSON
        const prevToken = i === 0 ? token : arr[i - 1];
        if (token.type === 'string' &&
            prevToken.type === 'whitespace' &&
            /^\n\s+$/.test(prevToken.value)) {
            return { ...token, type: 'key' };
        }
        return token;
    })
        .map((token) => {
        const formatter = formatters[token.type] || identity;
        return formatter(token.raw);
    })
        .join('');
}
//# sourceMappingURL=colorizeJson.js.map