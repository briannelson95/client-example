"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.createHistoryStore = createHistoryStore;
exports.removeMissingReferences = void 0;

var _types = require("@sanity/types");

var _jsonReduce = _interopRequireDefault(require("json-reduce"));

var _rxjs = require("rxjs");

var _operators = require("rxjs/operators");

var _util = require("../../util");

var _history = require("./history");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const documentRevisionCache = Object.create(null);

const getHistory = function (client, documentIds) {
  let options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
  const ids = Array.isArray(documentIds) ? documentIds : [documentIds];
  const {
    time,
    revision
  } = options;

  if (time && revision) {
    throw new Error("getHistory can't handle both time and revision parameters");
  }

  const dataset = client.clientConfig.dataset;
  let url = "/data/history/".concat(dataset, "/documents/").concat(ids.join(','));

  if (revision) {
    url = "".concat(url, "?revision=").concat(revision);
  } else {
    const timestamp = time || new Date().toISOString();
    url = "".concat(url, "?time=").concat(timestamp);
  }

  return client.request({
    url
  });
};

const getDocumentAtRevision = (client, documentId, revision) => {
  const publishedId = (0, _util.getPublishedId)(documentId);
  const draftId = (0, _util.getDraftId)(documentId);
  const cacheKey = "".concat(publishedId, "@").concat(revision);
  const cached = documentRevisionCache[cacheKey];

  if (cached) {
    return cached;
  }

  const dataset = client.clientConfig.dataset;
  const url = "/data/history/".concat(dataset, "/documents/").concat(publishedId, ",").concat(draftId, "?revision=").concat(revision);
  const entry = client.request({
    url
  }).then(result => {
    const documents = result.documents || [];
    const published = documents.find(res => res._id === publishedId);
    const draft = documents.find(res => res._id === draftId);
    return draft || published;
  });
  documentRevisionCache[cacheKey] = entry;
  return entry;
};

const getTransactions = async (client, documentIds) => {
  const ids = Array.isArray(documentIds) ? documentIds : [documentIds];
  const dataset = client.clientConfig.dataset;
  const query = {
    excludeContent: 'true',
    includeIdentifiedDocumentsOnly: 'true'
  };
  const url = "/data/history/".concat(dataset, "/transactions/").concat(ids.join(','));
  const result = await client.request({
    url,
    query
  });
  const transactions = result.toString('utf8').split('\n').filter(Boolean).map(line => JSON.parse(line));
  return transactions;
};

const getAllRefIds = doc => (0, _jsonReduce.default)(doc, (acc, node) => (0, _types.isReference)(node) && !acc.includes(node._ref) ? [...acc, node._ref] : acc, []);

function jsonMap(value, mapFn) {
  if (Array.isArray(value)) {
    return mapFn(value.map(item => jsonMap(item, mapFn)).filter(item => typeof item !== 'undefined'));
  }

  if ((0, _util.isRecord)(value)) {
    return mapFn(Object.keys(value).reduce((res, key) => {
      const mappedValue = jsonMap(value[key], mapFn);

      if (typeof mappedValue !== 'undefined') {
        res[key] = mappedValue;
      }

      return res;
    }, {}));
  }

  return mapFn(value);
}

const mapRefNodes = (doc, mapFn) => jsonMap(doc, node => (0, _types.isReference)(node) ? mapFn(node) : node);

const removeMissingReferences = (doc, existingIds) => mapRefNodes(doc, refNode => {
  const documentExists = existingIds[refNode._ref];
  return documentExists ? refNode : undefined;
});

exports.removeMissingReferences = removeMissingReferences;

function restore(client, documentId, targetDocumentId, rev) {
  return (0, _rxjs.from)(getDocumentAtRevision(client, documentId, rev)).pipe((0, _operators.mergeMap)(documentAtRevision => {
    if (!documentAtRevision) {
      throw new Error("Unable to find document with ID ".concat(documentId, " at revision ").concat(rev));
    }

    const existingIdsQuery = getAllRefIds(documentAtRevision).map(refId => "\"".concat(refId, "\": defined(*[_id==\"").concat(refId, "\"]._id)")).join(',');
    return client.observable.fetch("{".concat(existingIdsQuery, "}")).pipe((0, _operators.map)(existingIds => removeMissingReferences(documentAtRevision, existingIds)));
  }), (0, _operators.map)(documentAtRevision => {
    // Remove _updatedAt and create a new draft from the document at given revision
    const {
      _updatedAt,
      ...document
    } = documentAtRevision;
    return { ...document,
      _id: targetDocumentId
    };
  }), (0, _operators.mergeMap)(restoredDraft => client.observable.createOrReplace(restoredDraft, {
    visibility: 'async'
  })));
}

function createHistoryStore(_ref) {
  let {
    client
  } = _ref;
  return {
    getDocumentAtRevision: (documentId, revision) => getDocumentAtRevision(client, documentId, revision),
    getHistory: (documentIds, options) => getHistory(client, documentIds, options),
    getTransactions: documentIds => getTransactions(client, documentIds),
    restore: (id, targetId, rev) => restore(client, id, targetId, rev),
    getTimeline: options => new _history.Timeline(options),
    getTimelineController: options => (0, _history.createObservableController)(options)
  };
}