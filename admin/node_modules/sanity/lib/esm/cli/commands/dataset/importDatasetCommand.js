import path from 'path';
import fs from 'fs/promises';
import { createReadStream } from 'fs';
import getIt from 'get-it';
import { promise } from 'get-it/middleware';
import sanityImport from '@sanity/import';
import padStart from 'lodash/padStart';
import prettyMs from 'pretty-ms';
import { chooseDatasetPrompt } from '../../actions/dataset/chooseDatasetPrompt';
import { validateDatasetName } from '../../actions/dataset/validateDatasetName';
import { debug } from '../../debug';

const yellow = str => "\x1B[33m".concat(str, "\x1B[39m");

const helpText = "\nOptions\n  --missing On duplicate document IDs, skip importing document in question\n  --replace On duplicate document IDs, replace existing document with imported document\n  --allow-failing-assets Skip assets that cannot be fetched/uploaded\n  --replace-assets Skip reuse of existing assets\n\nRarely used options (should generally not be used)\n  --allow-assets-in-different-dataset Allow asset documents to reference different project/dataset\n\nExamples\n  # Import \"moviedb.ndjson\" from the current directory to the dataset called \"moviedb\"\n  sanity dataset import moviedb.ndjson moviedb\n\n  # Import \"moviedb.tar.gz\" from the current directory to the dataset called \"moviedb\",\n  # replacing any documents encountered that have the same document IDs\n  sanity dataset import moviedb.tar.gz moviedb --replace\n\n  # Import from a folder containing an ndjson file, such as an extracted tarball\n  # retrieved through \"sanity dataset export\".\n  sanity dataset import ~/some/folder moviedb\n\n  # Import from a remote URL. Will download and extract the tarball to a temporary\n  # location before importing it.\n  sanity dataset import https://some.url/moviedb.tar.gz moviedb --replace\n";

function toBoolIfSet(flag) {
  return typeof flag === 'undefined' ? undefined : Boolean(flag);
}

function parseFlags(rawFlags) {
  const allowAssetsInDifferentDataset = toBoolIfSet(rawFlags['allow-assets-in-different-dataset']);
  const allowFailingAssets = toBoolIfSet(rawFlags['allow-failing-assets']);
  const assetConcurrency = toBoolIfSet(rawFlags['asset-concurrency']);
  const replaceAssets = toBoolIfSet(rawFlags['replace-assets']);
  const replace = toBoolIfSet(rawFlags.replace);
  const missing = toBoolIfSet(rawFlags.missing);
  return {
    allowAssetsInDifferentDataset,
    allowFailingAssets,
    assetConcurrency,
    replaceAssets,
    replace,
    missing
  };
}

const importDatasetCommand = {
  name: 'import',
  group: 'dataset',
  signature: '[FILE | FOLDER | URL] [TARGET_DATASET]',
  description: 'Import documents to given dataset from ndjson file',
  helpText,
  // eslint-disable-next-line max-statements
  action: async (args, context) => {
    const {
      apiClient,
      output,
      chalk,
      fromInitCommand
    } = context;
    const flags = parseFlags(args.extOptions);
    const {
      allowAssetsInDifferentDataset,
      allowFailingAssets,
      assetConcurrency,
      replaceAssets
    } = flags;
    const operation = getMutationOperation(args.extOptions);
    const client = apiClient();
    const [file, target] = args.argsWithoutOptions;

    if (!file) {
      throw new Error("Source file name and target dataset must be specified (\"sanity dataset import ".concat(chalk.bold('[file]'), " [dataset]\")"));
    }

    const targetDataset = await determineTargetDataset(target, context);
    debug("Target dataset has been set to \"".concat(targetDataset, "\""));
    const isUrl = /^https?:\/\//i.test(file);
    let inputStream;
    let assetsBase;
    let sourceIsFolder = false;

    if (isUrl) {
      debug('Input is a URL, streaming from source URL');
      inputStream = await getUrlStream(file);
    } else {
      const sourceFile = path.resolve(process.cwd(), file);
      const fileStats = await fs.stat(sourceFile).catch(() => null);

      if (!fileStats) {
        throw new Error("".concat(sourceFile, " does not exist or is not readable"));
      }

      sourceIsFolder = fileStats.isDirectory();

      if (sourceIsFolder) {
        inputStream = sourceFile;
      } else {
        assetsBase = path.dirname(sourceFile);
        inputStream = await createReadStream(sourceFile);
      }
    }

    const importClient = client.clone().config({
      dataset: targetDataset
    });
    let currentStep;
    let currentProgress;
    let stepStart;
    let spinInterval = null;
    let percent;

    function onProgress(opts) {
      const lengthComputable = opts.total;
      const sameStep = opts.step == currentStep;
      percent = getPercentage(opts);

      if (lengthComputable && opts.total === opts.current) {
        if (spinInterval) {
          clearInterval(spinInterval);
        }

        spinInterval = null;
      }

      if (sameStep) {
        return;
      } // Moved to a new step


      const prevStep = currentStep;
      const prevStepStart = stepStart || Date.now();
      stepStart = Date.now();
      currentStep = opts.step;

      if (currentProgress && currentProgress.succeed) {
        const timeSpent = prettyMs(Date.now() - prevStepStart, {
          secondsDecimalDigits: 2
        });
        currentProgress.text = "[100%] ".concat(prevStep, " (").concat(timeSpent, ")");
        currentProgress.succeed();
      }

      currentProgress = output.spinner("[0%] ".concat(opts.step, " (0.00s)")).start();

      if (spinInterval) {
        clearInterval(spinInterval);
        spinInterval = null;
      }

      spinInterval = setInterval(() => {
        const timeSpent = prettyMs(Date.now() - prevStepStart, {
          secondsDecimalDigits: 2
        });

        if (currentProgress) {
          currentProgress.text = "".concat(percent).concat(opts.step, " (").concat(timeSpent, ")");
        }
      }, 60);
    }

    function endTask(_ref) {
      let {
        success
      } = _ref;

      if (spinInterval) {
        clearInterval(spinInterval);
      }

      spinInterval = null;

      if (success && stepStart && currentProgress) {
        const timeSpent = prettyMs(Date.now() - stepStart, {
          secondsDecimalDigits: 2
        });
        currentProgress.text = "[100%] ".concat(currentStep, " (").concat(timeSpent, ")");
        currentProgress.succeed();
      } else if (currentProgress) {
        currentProgress.fail();
      }
    } // Start the import!


    try {
      const {
        numDocs,
        warnings
      } = await sanityImport(inputStream, {
        client: importClient,
        assetsBase,
        operation,
        onProgress,
        allowFailingAssets,
        allowAssetsInDifferentDataset,
        assetConcurrency,
        replaceAssets
      });
      endTask({
        success: true
      });
      output.print('Done! Imported %d documents to dataset "%s"\n', numDocs, targetDataset);
      printWarnings(warnings, output);
    } catch (err) {
      endTask({
        success: false
      });
      const isNonRefConflict = !fromInitCommand && err.response && err.response.statusCode === 409 && err.step !== 'strengthen-references';

      if (!isNonRefConflict) {
        throw err;
      }

      const message = [err.message, '', 'You probably want either:', ' --replace (replace existing documents with same IDs)', ' --missing (only import documents that do not already exist)', ''].join('\n'); // @todo SUBCLASS ERROR?

      const error = new Error(message);
      error.details = err.details;
      error.response = err.response;
      error.responseBody = err.responseBody;
      throw error;
    }
  }
};

async function determineTargetDataset(target, context) {
  const {
    apiClient,
    output,
    prompt
  } = context;
  const client = apiClient();

  if (target) {
    const dsError = validateDatasetName(target);

    if (dsError) {
      throw new Error(dsError);
    }
  }

  debug('Fetching available datasets');
  const spinner = output.spinner('Fetching available datasets').start();
  const datasets = await client.datasets.list();
  spinner.succeed('[100%] Fetching available datasets');
  let targetDataset = target ? "".concat(target) : null;

  if (!targetDataset) {
    targetDataset = await chooseDatasetPrompt(context, {
      message: 'Select target dataset',
      allowCreation: true
    });
  } else if (!datasets.find(dataset => dataset.name === targetDataset)) {
    debug('Target dataset does not exist, prompting for creation');
    const shouldCreate = await prompt.single({
      type: 'confirm',
      message: "Dataset \"".concat(targetDataset, "\" does not exist, would you like to create it?"),
      default: true
    });

    if (!shouldCreate) {
      throw new Error("Dataset \"".concat(targetDataset, "\" does not exist"));
    }

    await client.datasets.create(targetDataset);
  }

  return targetDataset;
}

function getMutationOperation(flags) {
  const {
    replace,
    missing
  } = flags;

  if (replace && missing) {
    throw new Error('Cannot use both --replace and --missing');
  }

  if (flags.replace) {
    return 'createOrReplace';
  }

  if (flags.missing) {
    return 'createIfNotExists';
  }

  return 'create';
}

function getPercentage(opts) {
  if (!opts.total || typeof opts.current === 'undefined') {
    return '';
  }

  const percent = Math.floor(opts.current / opts.total * 100);
  return "[".concat(padStart("".concat(percent), 3, ' '), "%] ");
}

function getUrlStream(url) {
  const request = getIt([promise({
    onlyBody: true
  })]);
  return request({
    url,
    stream: true
  });
}

function printWarnings(warnings, output) {
  const assetFails = warnings.filter(warn => warn.type === 'asset');

  if (!assetFails.length) {
    return;
  }

  const warn = (output.warn || output.print).bind(output);
  warn(yellow('âš  Failed to import the following %s:'), assetFails.length > 1 ? 'assets' : 'asset');
  warnings.forEach(warning => {
    warn("  ".concat(warning.url));
  });
}

export default importDatasetCommand;