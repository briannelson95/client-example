import { mergeMap, map, catchError } from 'rxjs/operators';
import { Observable, of as observableOf } from 'rxjs';
import { withMaxConcurrency } from '../../utils';
const MAX_CONCURRENT_UPLOADS = 4;

function uploadSanityAsset(client, assetType, file) {
  let options = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};
  const extract = options.metadata;
  const preserveFilename = options.storeOriginalFilename;
  const {
    label,
    title,
    description,
    creditLine,
    source
  } = options;
  return hashFile(file).pipe(catchError(() => // ignore if hashing fails for some reason
  observableOf(null)), mergeMap(hash => // note: the sanity api will still dedupe unique files, but this saves us from uploading the asset file entirely
  hash ? fetchExisting(client, "sanity.".concat(assetType, "Asset"), hash) : observableOf(null)), mergeMap(existing => {
    if (existing) {
      return observableOf({
        // complete with the existing asset document
        type: 'complete',
        id: existing._id,
        asset: existing
      });
    }

    return client.observable.assets.upload(assetType, file, {
      tag: 'asset.upload',
      extract,
      preserveFilename,
      label,
      title,
      description,
      creditLine,
      source
    }).pipe(map(event => event.type === 'response' ? {
      // rewrite to a 'complete' event
      type: 'complete',
      id: event.body.document._id,
      asset: event.body.document
    } : event));
  }));
}

const uploadAsset = withMaxConcurrency(uploadSanityAsset, MAX_CONCURRENT_UPLOADS);
export const uploadImageAsset = (client, file, options) => uploadAsset(client, 'image', file, options);
export const uploadFileAsset = (client, file, options) => uploadAsset(client, 'file', file, options); // note: there's currently 100% overlap between the ImageAsset document and the FileAsset documents as per interface required by the image and file input

function observeAssetDoc(documentPreviewStore, id) {
  return documentPreviewStore.observePaths({
    _type: 'reference',
    _ref: id
  }, ['originalFilename', 'url', 'metadata', 'label', 'title', 'description', 'creditLine', 'source', 'size']);
}

export function observeImageAsset(documentPreviewStore, id) {
  return observeAssetDoc(documentPreviewStore, id);
}
export function observeFileAsset(documentPreviewStore, id) {
  return observeAssetDoc(documentPreviewStore, id);
}

function fetchExisting(client, type, hash) {
  return client.observable.fetch('*[_type == $documentType && sha1hash == $hash][0]', {
    documentType: type,
    hash
  }, {
    tag: 'asset.find-duplicate'
  });
}

function readFile(file) {
  return new Observable(subscriber => {
    const reader = new FileReader();

    reader.onload = () => {
      subscriber.next(reader.result);
      subscriber.complete();
    };

    reader.onerror = err => {
      subscriber.error(err);
    };

    reader.readAsArrayBuffer(file);
    return () => {
      reader.abort();
    };
  });
}

function hashFile(file) {
  if (!window.crypto || !window.crypto.subtle || !window.FileReader) {
    return observableOf(null);
  }

  return readFile(file).pipe(mergeMap(arrayBuffer => crypto.subtle.digest('SHA-1', arrayBuffer)), map(hexFromBuffer));
}

function hexFromBuffer(buffer) {
  return Array.prototype.map.call(new Uint8Array(buffer), x => "00".concat(x.toString(16)).slice(-2)).join('');
}